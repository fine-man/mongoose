{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "sys.path.append(os.path.join(cur_dir, \"lsh_lib\"))\n",
    "sys.path.append(os.path.join(cur_dir, \"mongoose_slide\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clsh import pyLSH\n",
    "from mongoose_slide.slide_lib.lsh import LSH\n",
    "# from mongoose_slide.slide_lib.simHash import SimHash\n",
    "from mongoose_slide.slide_lib.projectionHash import RandomProjection\n",
    "\n",
    "from src.lsh_layer import LSHLayer\n",
    "from src.models.simple_mlp import SimpleMLP\n",
    "from src.models.two_layer_lsh import TwoLayerLSH\n",
    "from src.utils import train, train_lsh, eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some magic so that the notebook will reload external python modules;\n",
    "# see https://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CIFAR100 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "size of train dataset: 50000\n",
      "size of test dataset: 10000\n",
      "['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
     ]
    }
   ],
   "source": [
    "# Define the transformations for data pre-processing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load the CIFAR100 training dataset\n",
    "trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "# Load the CIFAR100 test dataset\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create a data loader for the training dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "# Create a data loader for the test dataset\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "# Define the classes in CIFAR100\n",
    "classes = trainset.classes\n",
    "\n",
    "print(f\"size of train dataset: {len(trainset)}\")\n",
    "print(f\"size of test dataset: {len(testset)}\")\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "tensor(-0.9922) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "for x, y in trainset:\n",
    "    print(x.shape)\n",
    "    # print(y.shape)\n",
    "    print(x.min(), x.max())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal MLP on CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "input_size = 3 * 32 * 32\n",
    "hidden_size = 10000\n",
    "num_classes = len(classes)\n",
    "\n",
    "model = SimpleMLP(input_size, hidden_size, num_classes, flatten_first=True)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch time: 24.03 seconds\n",
      "Epoch [1/2] | Train Loss: 3.1828 | Train Acc: 23.51% | Test Loss: 3.4957 | Test Acc: 18.24\n",
      "\n",
      "Epoch time: 23.85 seconds\n",
      "Epoch [2/2] | Train Loss: 2.8843 | Train Acc: 29.66% | Test Loss: 3.4435 | Test Acc: 20.91\n",
      "\n",
      "Total training time: 90.02 seconds\n"
     ]
    }
   ],
   "source": [
    "model = train(model, trainloader, criterion, optimizer, testloader, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSH MLP on CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "input_size = 3 * 32 * 32    \n",
    "num_epochs = 20\n",
    "hidden_size = 10000\n",
    "num_classes = len(classes)\n",
    "K = 10\n",
    "L = 50\n",
    "threads = 1\n",
    "model_lsh = TwoLayerLSH(input_size, hidden_size, num_classes, K, L, threads, flatten_first=True)\n",
    "\n",
    "model_lsh = model_lsh.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_lsh.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average activations: 1770.09048 | Average Epoch activations: 1770.09048\n",
      "Epoch time: 44.90 seconds\n",
      "Epoch [1/20] | Train Loss: 102.1975 | Train Acc: 17.84% | Test Loss: 151.7277 | Test Acc: 8.96\n",
      "\n",
      "Average activations: 1745.85068 | Average Epoch activations: 1721.61088\n",
      "Epoch time: 44.89 seconds\n",
      "Epoch [2/20] | Train Loss: 87.7242 | Train Acc: 23.22% | Test Loss: 156.6249 | Test Acc: 9.13\n",
      "\n",
      "Average activations: 1732.8477866666667 | Average Epoch activations: 1706.842\n",
      "Epoch time: 46.99 seconds\n",
      "Epoch [3/20] | Train Loss: 93.4997 | Train Acc: 24.53% | Test Loss: 177.8033 | Test Acc: 8.83\n",
      "\n",
      "Average activations: 1722.38764 | Average Epoch activations: 1691.0072\n",
      "Epoch time: 45.84 seconds\n",
      "Epoch [4/20] | Train Loss: 86.2459 | Train Acc: 27.25% | Test Loss: 183.6157 | Test Acc: 9.27\n",
      "\n",
      "Average activations: 1714.139632 | Average Epoch activations: 1681.1476\n",
      "Epoch time: 47.05 seconds\n",
      "Epoch [5/20] | Train Loss: 88.7877 | Train Acc: 28.23% | Test Loss: 203.1035 | Test Acc: 9.18\n",
      "\n",
      "Average activations: 1705.9587333333334 | Average Epoch activations: 1665.05424\n",
      "Epoch time: 44.73 seconds\n",
      "Epoch [6/20] | Train Loss: 91.1004 | Train Acc: 29.01% | Test Loss: 223.3881 | Test Acc: 8.75\n",
      "\n",
      "Average activations: 1699.24472 | Average Epoch activations: 1658.96064\n",
      "Epoch time: 46.05 seconds\n",
      "Epoch [7/20] | Train Loss: 96.1003 | Train Acc: 29.34% | Test Loss: 236.4185 | Test Acc: 9.26\n",
      "\n",
      "Average activations: 1693.06524 | Average Epoch activations: 1649.80888\n",
      "Epoch time: 44.80 seconds\n",
      "Epoch [8/20] | Train Loss: 102.3839 | Train Acc: 29.95% | Test Loss: 261.9196 | Test Acc: 9.18\n",
      "\n",
      "Average activations: 1687.5943733333334 | Average Epoch activations: 1643.82744\n",
      "Epoch time: 46.51 seconds\n",
      "Epoch [9/20] | Train Loss: 95.4531 | Train Acc: 30.83% | Test Loss: 266.8989 | Test Acc: 9.20\n",
      "\n",
      "Average activations: 1682.092992 | Average Epoch activations: 1632.58056\n",
      "Epoch time: 46.49 seconds\n",
      "Epoch [10/20] | Train Loss: 102.7996 | Train Acc: 31.19% | Test Loss: 288.9766 | Test Acc: 9.72\n",
      "\n",
      "Average activations: 1676.9582763636363 | Average Epoch activations: 1625.61112\n",
      "Epoch time: 45.61 seconds\n",
      "Epoch [11/20] | Train Loss: 107.5342 | Train Acc: 30.92% | Test Loss: 305.7453 | Test Acc: 9.63\n",
      "\n",
      "Average activations: 1672.0245733333334 | Average Epoch activations: 1617.75384\n",
      "Epoch time: 46.69 seconds\n",
      "Epoch [12/20] | Train Loss: 115.1036 | Train Acc: 31.03% | Test Loss: 338.0553 | Test Acc: 9.02\n",
      "\n",
      "Average activations: 1667.368363076923 | Average Epoch activations: 1611.49384\n",
      "Epoch time: 45.99 seconds\n",
      "Epoch [13/20] | Train Loss: 121.9950 | Train Acc: 30.74% | Test Loss: 361.6749 | Test Acc: 9.38\n",
      "\n",
      "Average activations: 1663.0136685714285 | Average Epoch activations: 1606.40264\n",
      "Epoch time: 45.81 seconds\n",
      "Epoch [14/20] | Train Loss: 120.4346 | Train Acc: 31.72% | Test Loss: 377.7095 | Test Acc: 9.05\n",
      "\n",
      "Average activations: 1658.633584 | Average Epoch activations: 1597.3124\n",
      "Epoch time: 46.43 seconds\n",
      "Epoch [15/20] | Train Loss: 138.3600 | Train Acc: 30.63% | Test Loss: 412.5439 | Test Acc: 9.44\n",
      "\n",
      "Average activations: 1654.518165 | Average Epoch activations: 1592.78688\n",
      "Epoch time: 46.33 seconds\n",
      "Epoch [16/20] | Train Loss: 139.6005 | Train Acc: 30.82% | Test Loss: 432.0024 | Test Acc: 9.82\n",
      "\n",
      "Average activations: 1650.4647341176471 | Average Epoch activations: 1585.60984\n",
      "Epoch time: 44.68 seconds\n",
      "Epoch [17/20] | Train Loss: 148.2689 | Train Acc: 30.85% | Test Loss: 470.9371 | Test Acc: 9.23\n",
      "\n",
      "Average activations: 1646.4655777777778 | Average Epoch activations: 1578.47992\n",
      "Epoch time: 45.75 seconds\n",
      "Epoch [18/20] | Train Loss: 166.0373 | Train Acc: 30.61% | Test Loss: 517.6610 | Test Acc: 9.53\n",
      "\n",
      "Average activations: 1642.3821936842105 | Average Epoch activations: 1568.88128\n",
      "Epoch time: 44.31 seconds\n",
      "Epoch [19/20] | Train Loss: 164.9881 | Train Acc: 30.67% | Test Loss: 536.0909 | Test Acc: 9.35\n",
      "\n",
      "Average activations: 1638.309468 | Average Epoch activations: 1560.92768\n",
      "Epoch time: 46.48 seconds\n",
      "Epoch [20/20] | Train Loss: 176.6691 | Train Acc: 30.47% | Test Loss: 573.8685 | Test Acc: 8.88\n",
      "\n",
      "Total training time: 1592.63 seconds\n"
     ]
    }
   ],
   "source": [
    "model_lsh = train_lsh(model_lsh, trainloader, criterion, optimizer, testloader, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
